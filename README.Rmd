---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# SimHelpers

<!-- badges: start -->
<!-- badges: end -->

The goal of SimHelpers is to help with running simulation studies. It calculates performance criteria measures, Monte Carlo Standard Errors...(under development).

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("meghapsimatrix/SimHelpers")
```
## Example

This is a basic example which shows you how to solve a common problem. We use the `welch_res` dataset included in the package. Here we are calculating the absolute performance criteria for the estimate of the mean difference. We present the results by method and mean difference (conditions which were varied to generate the `welch_res` data).


```{r example, message = FALSE, warning = FALSE}
library(SimHelpers)
library(tidyverse)
library(knitr)


welch_res %>%
  group_by(method, mean_diff) %>%
  do(calc_abs(.,  estimates = est, true_param = .$mean_diff[1])) %>%
  kable()
```

Below, we calculate the relative criteria for the mean difference estimates. Note that when mean difference is 0, the relative measures cannot be calculated. The function returns `NA` values for conditions where the mean difference is 0. 

```{r}
welch_res %>%
  group_by(method, mean_diff) %>%
  do(calc_relative(., estimates = est, true_param = .$mean_diff[1])) %>%
  kable()

```


Below we calculate the rejection rate performance criteria for the hypothesis tests done using t-test.  

```{r}
welch_res %>%
  group_by(method, mean_diff) %>%
  do(calc_rr(., p_values = p_val)) %>%
  kable()
```


Below we calculate the coverage and width performance criteria for the confidence intervals for the estimate of the mean difference.

```{r}
welch_res %>%
  group_by(method, mean_diff) %>%
  do(calc_coverage(., lower_bound = lower_bound, upper_bound = upper_bound, true_param = .$mean_diff[1])) %>%
  kable()
```


# Jacknife MCSE for variance estimates

UNDER DEVELOPMENT :) 

```{r}
calc_jacknife(res_dat = alpha_res, estimates = var_est, true_param = .8) %>%
  kable()
```

